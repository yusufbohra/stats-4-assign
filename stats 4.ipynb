{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32774b27-ec7a-4dbe-b772-20500f634acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Both t-tests and z-tests are statistical methods used to make inferences about population parameters based on sample data. They are commonly used in hypothesis testing and confidence interval estimation. The key difference between these tests lies in the assumptions about the population parameters and the sample sizes.\\n\\n**Z-Test:**\\n- A z-test is used when you have a large sample size (typically n > 30) or when the population standard deviation is known.\\n- It assumes that the population follows a normal distribution.\\n- It involves comparing the sample mean to a known population mean.\\n- The test statistic is calculated using the z-score formula: \\\\( z = \\x0crac{\\x08ar{x} - \\\\mu}{\\x0crac{\\\\sigma}{\\\\sqrt{n}}} \\\\).\\n- Commonly used for scenarios where the sample size is large, such as assessing the effectiveness of a new drug on a large population.\\n\\n**T-Test:**\\n- A t-test is used when you have a small sample size (typically n < 30) or when the population standard deviation is unknown.\\n- It assumes that the population follows a normal distribution.\\n- It involves comparing the sample mean to a hypothesized population mean.\\n- The test statistic is calculated using the t-score formula: \\\\( t = \\x0crac{\\x08ar{x} - \\\\mu}{\\x0crac{s}{\\\\sqrt{n}}} \\\\).\\n- There are different types of t-tests, such as one-sample t-test, two-sample t-test, and paired t-test.\\n- Commonly used for scenarios with small sample sizes, like comparing the means of two groups of students who received different teaching methods.\\n\\n**Example Scenarios:**\\n\\n1. **Z-Test:**\\n   Imagine you're conducting a survey on the average income of people in a large city. You have access to census data that provides the population standard deviation. Since the sample size is large (thousands of respondents), you can use a z-test to determine whether the average income of your sample significantly differs from the known population average income.\\n\\n2. **T-Test:**\\n   Consider you're evaluating the effectiveness of a new workout program on a small group of participants. You collect data from 20 participants and measure their weight loss after following the program. Since the population standard deviation is unknown and the sample size is small, you would use a one-sample t-test to determine whether the average weight loss is statistically significant.\\n\\nIn summary, the choice between a z-test and a t-test depends on factors such as the sample size, knowledge of population parameters, and whether the population standard deviation is known. Z-tests are used for larger sample sizes or known population standard deviations, while t-tests are used for smaller sample sizes or unknown population standard deviations.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 1\n",
    "\"\"\"Both t-tests and z-tests are statistical methods used to make inferences about population parameters based on sample data. They are commonly used in hypothesis testing and confidence interval estimation. The key difference between these tests lies in the assumptions about the population parameters and the sample sizes.\n",
    "\n",
    "**Z-Test:**\n",
    "- A z-test is used when you have a large sample size (typically n > 30) or when the population standard deviation is known.\n",
    "- It assumes that the population follows a normal distribution.\n",
    "- It involves comparing the sample mean to a known population mean.\n",
    "- The test statistic is calculated using the z-score formula: \\( z = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\).\n",
    "- Commonly used for scenarios where the sample size is large, such as assessing the effectiveness of a new drug on a large population.\n",
    "\n",
    "**T-Test:**\n",
    "- A t-test is used when you have a small sample size (typically n < 30) or when the population standard deviation is unknown.\n",
    "- It assumes that the population follows a normal distribution.\n",
    "- It involves comparing the sample mean to a hypothesized population mean.\n",
    "- The test statistic is calculated using the t-score formula: \\( t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}} \\).\n",
    "- There are different types of t-tests, such as one-sample t-test, two-sample t-test, and paired t-test.\n",
    "- Commonly used for scenarios with small sample sizes, like comparing the means of two groups of students who received different teaching methods.\n",
    "\n",
    "**Example Scenarios:**\n",
    "\n",
    "1. **Z-Test:**\n",
    "   Imagine you're conducting a survey on the average income of people in a large city. You have access to census data that provides the population standard deviation. Since the sample size is large (thousands of respondents), you can use a z-test to determine whether the average income of your sample significantly differs from the known population average income.\n",
    "\n",
    "2. **T-Test:**\n",
    "   Consider you're evaluating the effectiveness of a new workout program on a small group of participants. You collect data from 20 participants and measure their weight loss after following the program. Since the population standard deviation is unknown and the sample size is small, you would use a one-sample t-test to determine whether the average weight loss is statistically significant.\n",
    "\n",
    "In summary, the choice between a z-test and a t-test depends on factors such as the sample size, knowledge of population parameters, and whether the population standard deviation is known. Z-tests are used for larger sample sizes or known population standard deviations, while t-tests are used for smaller sample sizes or unknown population standard deviations.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730d1624-499d-4f37-822f-564720a73ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One-tailed tests and two-tailed tests are two different approaches used in hypothesis testing to determine the significance of a sample statistic and make conclusions about a population parameter. They differ in how they consider the possible outcomes and how they define the critical regions for making decisions.\\n\\n**One-Tailed Test:**\\nIn a one-tailed test (also known as a one-sided test), the alternative hypothesis (Ha) specifies a direction of effect or difference. It tests whether the sample statistic is significantly larger or smaller than the hypothesized population parameter. There are two possible forms of one-tailed tests:\\n\\n1. **Upper-Tailed Test:** The alternative hypothesis suggests that the population parameter is greater than the hypothesized value. The critical region is in the right tail of the distribution.\\n\\n2. **Lower-Tailed Test:** The alternative hypothesis suggests that the population parameter is smaller than the hypothesized value. The critical region is in the left tail of the distribution.\\n\\n**Two-Tailed Test:**\\nIn a two-tailed test (also known as a two-sided test), the alternative hypothesis (Ha) does not specify a direction of effect or difference. It tests whether the sample statistic is significantly different from the hypothesized population parameter, either larger or smaller. The critical regions are split between the left and right tails of the distribution.\\n\\n**Key Differences:**\\n\\n1. **Hypotheses:**\\n   - One-Tailed: The alternative hypothesis specifies a direction of effect or difference.\\n   - Two-Tailed: The alternative hypothesis does not specify a direction.\\n\\n2. **Critical Regions:**\\n   - One-Tailed: The critical region is in only one tail of the distribution (left or right).\\n   - Two-Tailed: The critical regions are split between both tails of the distribution.\\n\\n3. **P-Values:**\\n   - One-Tailed: The p-value is calculated for the tail corresponding to the direction specified by the alternative hypothesis.\\n   - Two-Tailed: The p-value is calculated for both tails, and it represents the probability of observing a result as extreme as the sample statistic in either direction.\\n\\n4. **Decision Rule:**\\n   - One-Tailed: If the p-value is smaller than the chosen significance level (α), you reject the null hypothesis in favor of the alternative.\\n   - Two-Tailed: If the p-value is smaller than half of the chosen significance level (α/2) for each tail, you reject the null hypothesis.\\n\\n**Example:**\\n\\nSuppose you're testing a new drug's effect on reducing cholesterol levels. If you hypothesize that the drug will decrease cholesterol and only want to detect if it decreases significantly (but not if it increases significantly), you would use an upper-tailed one-tailed test. If you're open to detecting both significant increases and decreases in cholesterol, you would use a two-tailed test.\\n\\nIn summary, the choice between one-tailed and two-tailed tests depends on the research question, the direction of effect you're interested in, and whether you want to consider effects in both directions.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 2\n",
    "\"\"\"One-tailed tests and two-tailed tests are two different approaches used in hypothesis testing to determine the significance of a sample statistic and make conclusions about a population parameter. They differ in how they consider the possible outcomes and how they define the critical regions for making decisions.\n",
    "\n",
    "**One-Tailed Test:**\n",
    "In a one-tailed test (also known as a one-sided test), the alternative hypothesis (Ha) specifies a direction of effect or difference. It tests whether the sample statistic is significantly larger or smaller than the hypothesized population parameter. There are two possible forms of one-tailed tests:\n",
    "\n",
    "1. **Upper-Tailed Test:** The alternative hypothesis suggests that the population parameter is greater than the hypothesized value. The critical region is in the right tail of the distribution.\n",
    "\n",
    "2. **Lower-Tailed Test:** The alternative hypothesis suggests that the population parameter is smaller than the hypothesized value. The critical region is in the left tail of the distribution.\n",
    "\n",
    "**Two-Tailed Test:**\n",
    "In a two-tailed test (also known as a two-sided test), the alternative hypothesis (Ha) does not specify a direction of effect or difference. It tests whether the sample statistic is significantly different from the hypothesized population parameter, either larger or smaller. The critical regions are split between the left and right tails of the distribution.\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "1. **Hypotheses:**\n",
    "   - One-Tailed: The alternative hypothesis specifies a direction of effect or difference.\n",
    "   - Two-Tailed: The alternative hypothesis does not specify a direction.\n",
    "\n",
    "2. **Critical Regions:**\n",
    "   - One-Tailed: The critical region is in only one tail of the distribution (left or right).\n",
    "   - Two-Tailed: The critical regions are split between both tails of the distribution.\n",
    "\n",
    "3. **P-Values:**\n",
    "   - One-Tailed: The p-value is calculated for the tail corresponding to the direction specified by the alternative hypothesis.\n",
    "   - Two-Tailed: The p-value is calculated for both tails, and it represents the probability of observing a result as extreme as the sample statistic in either direction.\n",
    "\n",
    "4. **Decision Rule:**\n",
    "   - One-Tailed: If the p-value is smaller than the chosen significance level (α), you reject the null hypothesis in favor of the alternative.\n",
    "   - Two-Tailed: If the p-value is smaller than half of the chosen significance level (α/2) for each tail, you reject the null hypothesis.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Suppose you're testing a new drug's effect on reducing cholesterol levels. If you hypothesize that the drug will decrease cholesterol and only want to detect if it decreases significantly (but not if it increases significantly), you would use an upper-tailed one-tailed test. If you're open to detecting both significant increases and decreases in cholesterol, you would use a two-tailed test.\n",
    "\n",
    "In summary, the choice between one-tailed and two-tailed tests depends on the research question, the direction of effect you're interested in, and whether you want to consider effects in both directions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24a2f9e-8e7e-461a-aefc-882759b6d074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In hypothesis testing, Type 1 and Type 2 errors are two possible mistakes that can occur when making decisions about the null hypothesis (H0) and the alternative hypothesis (Ha). These errors represent the balance between making correct decisions and making incorrect decisions.\\n\\n**Type 1 Error (False Positive):**\\nA Type 1 error occurs when you reject the null hypothesis when it is actually true. In other words, you conclude that there is a significant effect, difference, or relationship when there is none in reality. The probability of committing a Type 1 error is denoted by the symbol \\\\( \\x07lpha \\\\), which is the chosen significance level.\\n\\n**Example Scenario for Type 1 Error:**\\nImagine a clinical trial for a new medical treatment. The null hypothesis is that the treatment has no effect on the disease. A Type 1 error occurs if the researchers mistakenly conclude that the treatment is effective (reject the null) when, in fact, it has no actual effect.\\n\\n**Type 2 Error (False Negative):**\\nA Type 2 error occurs when you fail to reject the null hypothesis when it is actually false. In other words, you conclude that there is no significant effect, difference, or relationship when there is one in reality. The probability of committing a Type 2 error is denoted by the symbol \\\\( \\x08eta \\\\).\\n\\n**Example Scenario for Type 2 Error:**\\nContinuing with the medical treatment example, a Type 2 error occurs if the researchers fail to conclude that the treatment is effective (fail to reject the null) when, in fact, it has a significant effect on the disease.\\n\\n**Trade-off between Type 1 and Type 2 Errors:**\\nThere is an inherent trade-off between Type 1 and Type 2 errors. As you decrease the probability of committing one type of error, the probability of committing the other type of error increases. This trade-off is influenced by factors such as the sample size, the chosen significance level (α), the effect size, and the variability of the data.\\n\\n**Statistical Power:**\\nThe power of a statistical test is the probability of correctly rejecting a false null hypothesis, thereby avoiding a Type 2 error. It is \\\\( 1 - \\x08eta \\\\), where \\\\( \\x08eta \\\\) is the probability of a Type 2 error. Higher power indicates a better ability to detect a true effect if it exists.\\n\\nIn summary, Type 1 and Type 2 errors are essential concepts in hypothesis testing that reflect the possibility of making incorrect decisions. Researchers need to balance these errors when designing experiments and interpreting results to ensure valid and reliable conclusions.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 3\n",
    "\"\"\"In hypothesis testing, Type 1 and Type 2 errors are two possible mistakes that can occur when making decisions about the null hypothesis (H0) and the alternative hypothesis (Ha). These errors represent the balance between making correct decisions and making incorrect decisions.\n",
    "\n",
    "**Type 1 Error (False Positive):**\n",
    "A Type 1 error occurs when you reject the null hypothesis when it is actually true. In other words, you conclude that there is a significant effect, difference, or relationship when there is none in reality. The probability of committing a Type 1 error is denoted by the symbol \\( \\alpha \\), which is the chosen significance level.\n",
    "\n",
    "**Example Scenario for Type 1 Error:**\n",
    "Imagine a clinical trial for a new medical treatment. The null hypothesis is that the treatment has no effect on the disease. A Type 1 error occurs if the researchers mistakenly conclude that the treatment is effective (reject the null) when, in fact, it has no actual effect.\n",
    "\n",
    "**Type 2 Error (False Negative):**\n",
    "A Type 2 error occurs when you fail to reject the null hypothesis when it is actually false. In other words, you conclude that there is no significant effect, difference, or relationship when there is one in reality. The probability of committing a Type 2 error is denoted by the symbol \\( \\beta \\).\n",
    "\n",
    "**Example Scenario for Type 2 Error:**\n",
    "Continuing with the medical treatment example, a Type 2 error occurs if the researchers fail to conclude that the treatment is effective (fail to reject the null) when, in fact, it has a significant effect on the disease.\n",
    "\n",
    "**Trade-off between Type 1 and Type 2 Errors:**\n",
    "There is an inherent trade-off between Type 1 and Type 2 errors. As you decrease the probability of committing one type of error, the probability of committing the other type of error increases. This trade-off is influenced by factors such as the sample size, the chosen significance level (α), the effect size, and the variability of the data.\n",
    "\n",
    "**Statistical Power:**\n",
    "The power of a statistical test is the probability of correctly rejecting a false null hypothesis, thereby avoiding a Type 2 error. It is \\( 1 - \\beta \\), where \\( \\beta \\) is the probability of a Type 2 error. Higher power indicates a better ability to detect a true effect if it exists.\n",
    "\n",
    "In summary, Type 1 and Type 2 errors are essential concepts in hypothesis testing that reflect the possibility of making incorrect decisions. Researchers need to balance these errors when designing experiments and interpreting results to ensure valid and reliable conclusions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929ca2ae-e081-4942-a957-028abfb4f314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bayes's Theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence. It provides a framework for incorporating prior knowledge and new information to make more informed decisions.\\n\\nThe theorem is often expressed using the following formula:\\n\\n\\\\[ P(A|B) = \\x0crac{P(B|A) \\\\cdot P(A)}{P(B)} \\\\]\\n\\nWhere:\\n- \\\\( P(A|B) \\\\) is the posterior probability of event A given evidence B.\\n- \\\\( P(B|A) \\\\) is the likelihood of evidence B given event A.\\n- \\\\( P(A) \\\\) is the prior probability of event A.\\n- \\\\( P(B) \\\\) is the probability of evidence B.\\n\\n**Example Scenario:**\\n\\nLet's consider a medical diagnosis scenario where we want to determine the probability of a patient having a certain disease given the results of a diagnostic test.\\n\\n1. **Prior Information:**\\n   - Let \\\\( A \\\\) be the event that the patient has the disease.\\n   - \\\\( P(A) \\\\) is our prior probability estimate of the patient having the disease based on general knowledge or prevalence rates.\\n\\n2. **Diagnostic Test:**\\n   - Let \\\\( B \\\\) be the event that the test result is positive.\\n   - \\\\( P(B|A) \\\\) is the likelihood of getting a positive test result if the patient actually has the disease.\\n   - \\\\( P(B|\\neg A) \\\\) is the likelihood of getting a positive test result if the patient does not have the disease (false positive rate).\\n\\n3. **Posterior Probability:**\\n   - \\\\( P(A|B) \\\\) is the probability of the patient having the disease given a positive test result.\\n\\nUsing Bayes's Theorem, we can calculate the updated probability of the patient having the disease after obtaining a positive test result:\\n\\n\\\\[ P(A|B) = \\x0crac{P(B|A) \\\\cdot P(A)}{P(B)} \\\\]\\n\\nHere's a simplified example with hypothetical values:\\n\\n- Prior probability: \\\\( P(A) = 0.05 \\\\) (5% of patients have the disease)\\n- Likelihood of positive test result given disease: \\\\( P(B|A) = 0.98 \\\\) (98% accuracy)\\n- Likelihood of positive test result without disease: \\\\( P(B|\\neg A) = 0.10 \\\\) (10% false positive rate)\\n- Probability of getting a positive test result: \\\\( P(B) = P(B|A) \\\\cdot P(A) + P(B|\\neg A) \\\\cdot P(\\neg A) \\\\)\\n\\nSuppose a patient gets a positive test result. We can plug these values into the formula to calculate the updated probability of the patient actually having the disease.\\n\\nBayes's Theorem is powerful because it allows us to incorporate new evidence (test results) into our existing knowledge (prior probability) to arrive at a more accurate conclusion (posterior probability). It's widely used in various fields, including medical diagnosis, machine learning, and decision-making.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 4\n",
    "\"\"\"Bayes's Theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence. It provides a framework for incorporating prior knowledge and new information to make more informed decisions.\n",
    "\n",
    "The theorem is often expressed using the following formula:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the posterior probability of event A given evidence B.\n",
    "- \\( P(B|A) \\) is the likelihood of evidence B given event A.\n",
    "- \\( P(A) \\) is the prior probability of event A.\n",
    "- \\( P(B) \\) is the probability of evidence B.\n",
    "\n",
    "**Example Scenario:**\n",
    "\n",
    "Let's consider a medical diagnosis scenario where we want to determine the probability of a patient having a certain disease given the results of a diagnostic test.\n",
    "\n",
    "1. **Prior Information:**\n",
    "   - Let \\( A \\) be the event that the patient has the disease.\n",
    "   - \\( P(A) \\) is our prior probability estimate of the patient having the disease based on general knowledge or prevalence rates.\n",
    "\n",
    "2. **Diagnostic Test:**\n",
    "   - Let \\( B \\) be the event that the test result is positive.\n",
    "   - \\( P(B|A) \\) is the likelihood of getting a positive test result if the patient actually has the disease.\n",
    "   - \\( P(B|\\neg A) \\) is the likelihood of getting a positive test result if the patient does not have the disease (false positive rate).\n",
    "\n",
    "3. **Posterior Probability:**\n",
    "   - \\( P(A|B) \\) is the probability of the patient having the disease given a positive test result.\n",
    "\n",
    "Using Bayes's Theorem, we can calculate the updated probability of the patient having the disease after obtaining a positive test result:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Here's a simplified example with hypothetical values:\n",
    "\n",
    "- Prior probability: \\( P(A) = 0.05 \\) (5% of patients have the disease)\n",
    "- Likelihood of positive test result given disease: \\( P(B|A) = 0.98 \\) (98% accuracy)\n",
    "- Likelihood of positive test result without disease: \\( P(B|\\neg A) = 0.10 \\) (10% false positive rate)\n",
    "- Probability of getting a positive test result: \\( P(B) = P(B|A) \\cdot P(A) + P(B|\\neg A) \\cdot P(\\neg A) \\)\n",
    "\n",
    "Suppose a patient gets a positive test result. We can plug these values into the formula to calculate the updated probability of the patient actually having the disease.\n",
    "\n",
    "Bayes's Theorem is powerful because it allows us to incorporate new evidence (test results) into our existing knowledge (prior probability) to arrive at a more accurate conclusion (posterior probability). It's widely used in various fields, including medical diagnosis, machine learning, and decision-making.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d39d94e-1f20-4535-9b27-ef49f7f3b4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A confidence interval is a range of values that is used to estimate a population parameter, such as the population mean or proportion, along with a level of confidence that the true parameter lies within that range. It provides a measure of the uncertainty associated with the estimation and is often expressed as a range around a point estimate (like the sample mean).\\n\\nConfidence intervals are used to communicate the precision of an estimate. For example, if you have calculated a sample mean and its associated 95% confidence interval is [X, Y], it means that you are 95% confident that the true population mean lies between X and Y.\\n\\n**Calculating a Confidence Interval:**\\n\\nTo calculate a confidence interval, you typically use a formula that takes into account the sample data, the desired confidence level, and statistical properties. The formula for the confidence interval for a population mean when the population standard deviation is known is:\\n\\n\\\\[ \\text{Confidence Interval} = \\text{Sample Mean} \\\\pm \\text{Margin of Error} \\\\]\\n\\nThe margin of error depends on the desired confidence level, the sample size, and the population standard deviation (if known).\\n\\n**Example Scenario:**\\n\\nSuppose you are conducting a survey to estimate the average hours of sleep college students get per night. You collect data from a random sample of 100 students and find that the sample mean sleep hours is 7.5 hours, and the population standard deviation is 1.2 hours.\\n\\nYou want to calculate a 95% confidence interval for the true average sleep hours of all college students.\\n\\nUsing the formula for the confidence interval:\\n\\n\\\\[ \\text{Margin of Error} = \\text{Critical Value} \\times \\\\left( \\x0crac{\\text{Population Standard Deviation}}{\\\\sqrt{\\text{Sample Size}}} \\right) \\\\]\\n\\nWhere the critical value for a 95% confidence interval is approximately 1.96 (for a normal distribution).\\n\\nCalculating the margin of error:\\n\\n\\\\[ \\text{Margin of Error} = 1.96 \\times \\\\left( \\x0crac{1.2}{\\\\sqrt{100}} \\right) = 0.2352 \\\\]\\n\\nNow, you can calculate the confidence interval:\\n\\n\\\\[ \\text{Confidence Interval} = 7.5 \\\\pm 0.2352 = [7.2648, 7.7352] \\\\]\\n\\nThis means that you are 95% confident that the true average hours of sleep college students get per night is between 7.2648 and 7.7352 hours.\\n\\nIn summary, a confidence interval is a range of values that estimates a population parameter, and it accounts for the uncertainty associated with the estimation. It is calculated based on sample data, the desired confidence level, and appropriate statistical properties.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 5\n",
    "\"\"\"A confidence interval is a range of values that is used to estimate a population parameter, such as the population mean or proportion, along with a level of confidence that the true parameter lies within that range. It provides a measure of the uncertainty associated with the estimation and is often expressed as a range around a point estimate (like the sample mean).\n",
    "\n",
    "Confidence intervals are used to communicate the precision of an estimate. For example, if you have calculated a sample mean and its associated 95% confidence interval is [X, Y], it means that you are 95% confident that the true population mean lies between X and Y.\n",
    "\n",
    "**Calculating a Confidence Interval:**\n",
    "\n",
    "To calculate a confidence interval, you typically use a formula that takes into account the sample data, the desired confidence level, and statistical properties. The formula for the confidence interval for a population mean when the population standard deviation is known is:\n",
    "\n",
    "\\[ \\text{Confidence Interval} = \\text{Sample Mean} \\pm \\text{Margin of Error} \\]\n",
    "\n",
    "The margin of error depends on the desired confidence level, the sample size, and the population standard deviation (if known).\n",
    "\n",
    "**Example Scenario:**\n",
    "\n",
    "Suppose you are conducting a survey to estimate the average hours of sleep college students get per night. You collect data from a random sample of 100 students and find that the sample mean sleep hours is 7.5 hours, and the population standard deviation is 1.2 hours.\n",
    "\n",
    "You want to calculate a 95% confidence interval for the true average sleep hours of all college students.\n",
    "\n",
    "Using the formula for the confidence interval:\n",
    "\n",
    "\\[ \\text{Margin of Error} = \\text{Critical Value} \\times \\left( \\frac{\\text{Population Standard Deviation}}{\\sqrt{\\text{Sample Size}}} \\right) \\]\n",
    "\n",
    "Where the critical value for a 95% confidence interval is approximately 1.96 (for a normal distribution).\n",
    "\n",
    "Calculating the margin of error:\n",
    "\n",
    "\\[ \\text{Margin of Error} = 1.96 \\times \\left( \\frac{1.2}{\\sqrt{100}} \\right) = 0.2352 \\]\n",
    "\n",
    "Now, you can calculate the confidence interval:\n",
    "\n",
    "\\[ \\text{Confidence Interval} = 7.5 \\pm 0.2352 = [7.2648, 7.7352] \\]\n",
    "\n",
    "This means that you are 95% confident that the true average hours of sleep college students get per night is between 7.2648 and 7.7352 hours.\n",
    "\n",
    "In summary, a confidence interval is a range of values that estimates a population parameter, and it accounts for the uncertainty associated with the estimation. It is calculated based on sample data, the desired confidence level, and appropriate statistical properties.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbd2b7b-acc1-4e52-80ef-66dcbe38d1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! Let\\'s work through a sample problem using Bayes\\' Theorem to calculate the probability of an event occurring given prior knowledge and new evidence.\\n\\n**Sample Problem:**\\n\\nSuppose you are the manager of an online store, and you want to calculate the probability that a customer will make a purchase given two pieces of information:\\n\\n1. The probability that a customer makes a purchase on any given day is 0.25 (prior probability).\\n2. You know that when a customer visits the \"Sale\" section of your website, the probability of making a purchase increases to 0.6 (likelihood).\\n\\nYou also know that on a random day, the probability that a customer visits the \"Sale\" section is 0.3 (evidence).\\n\\n**Solution using Bayes\\' Theorem:**\\n\\nLet\\'s use Bayes\\' Theorem to calculate the probability of a customer making a purchase given that they visited the \"Sale\" section of your website:\\n\\n1. **Define Events:**\\n   - \\\\( A \\\\): Customer makes a purchase.\\n   - \\\\( B \\\\): Customer visits the \"Sale\" section.\\n\\n2. **Given Information:**\\n   - \\\\( P(A) = 0.25 \\\\) (prior probability of making a purchase)\\n   - \\\\( P(A\\') = 1 - P(A) = 0.75 \\\\) (probability of not making a purchase)\\n   - \\\\( P(B|A) = 0.6 \\\\) (likelihood of visiting \"Sale\" given purchase)\\n   - \\\\( P(B|A\\') = 0.3 \\\\) (likelihood of visiting \"Sale\" given no purchase)\\n   - \\\\( P(B) = 0.3 \\\\) (evidence of visiting \"Sale\")\\n\\n3. **Calculate the Posterior Probability using Bayes\\' Theorem:**\\n   Bayes\\' Theorem states: \\\\[ P(A|B) = \\x0crac{P(B|A) \\\\cdot P(A)}{P(B)} \\\\]\\n   \\n   Plugging in the values:\\n   \\\\[ P(A|B) = \\x0crac{P(B|A) \\\\cdot P(A)}{P(B)} = \\x0crac{0.6 \\\\cdot 0.25}{0.3} = 0.5 \\\\]\\n   \\n   Therefore, the probability that a customer will make a purchase given that they visited the \"Sale\" section is 0.5, or 50%.\\n\\nIn this example, we used Bayes\\' Theorem to update our initial probability estimate based on new evidence. The theorem allows us to incorporate prior knowledge (the probability of making a purchase) and new evidence (the probability of visiting the \"Sale\" section) to make a more informed estimate (the probability of making a purchase given visiting the \"Sale\" section).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 6\n",
    "\"\"\"Certainly! Let's work through a sample problem using Bayes' Theorem to calculate the probability of an event occurring given prior knowledge and new evidence.\n",
    "\n",
    "**Sample Problem:**\n",
    "\n",
    "Suppose you are the manager of an online store, and you want to calculate the probability that a customer will make a purchase given two pieces of information:\n",
    "\n",
    "1. The probability that a customer makes a purchase on any given day is 0.25 (prior probability).\n",
    "2. You know that when a customer visits the \"Sale\" section of your website, the probability of making a purchase increases to 0.6 (likelihood).\n",
    "\n",
    "You also know that on a random day, the probability that a customer visits the \"Sale\" section is 0.3 (evidence).\n",
    "\n",
    "**Solution using Bayes' Theorem:**\n",
    "\n",
    "Let's use Bayes' Theorem to calculate the probability of a customer making a purchase given that they visited the \"Sale\" section of your website:\n",
    "\n",
    "1. **Define Events:**\n",
    "   - \\( A \\): Customer makes a purchase.\n",
    "   - \\( B \\): Customer visits the \"Sale\" section.\n",
    "\n",
    "2. **Given Information:**\n",
    "   - \\( P(A) = 0.25 \\) (prior probability of making a purchase)\n",
    "   - \\( P(A') = 1 - P(A) = 0.75 \\) (probability of not making a purchase)\n",
    "   - \\( P(B|A) = 0.6 \\) (likelihood of visiting \"Sale\" given purchase)\n",
    "   - \\( P(B|A') = 0.3 \\) (likelihood of visiting \"Sale\" given no purchase)\n",
    "   - \\( P(B) = 0.3 \\) (evidence of visiting \"Sale\")\n",
    "\n",
    "3. **Calculate the Posterior Probability using Bayes' Theorem:**\n",
    "   Bayes' Theorem states: \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "   \n",
    "   Plugging in the values:\n",
    "   \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} = \\frac{0.6 \\cdot 0.25}{0.3} = 0.5 \\]\n",
    "   \n",
    "   Therefore, the probability that a customer will make a purchase given that they visited the \"Sale\" section is 0.5, or 50%.\n",
    "\n",
    "In this example, we used Bayes' Theorem to update our initial probability estimate based on new evidence. The theorem allows us to incorporate prior knowledge (the probability of making a purchase) and new evidence (the probability of visiting the \"Sale\" section) to make a more informed estimate (the probability of making a purchase given visiting the \"Sale\" section).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cea35f6-a0fe-4c5d-b808-10f6db58d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 50\n",
      "Confidence Interval: [48.21, 51.79]\n"
     ]
    }
   ],
   "source": [
    "#que 7\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "sample_mean = 50  # Sample mean\n",
    "sample_std_dev = 5  # Sample standard deviation\n",
    "sample_size = 30  # Sample size\n",
    "\n",
    "# Calculate the standard error of the sample mean\n",
    "standard_error = sample_std_dev / np.sqrt(sample_size)\n",
    "\n",
    "# Calculate the critical z-value for a 95% confidence interval\n",
    "critical_z_value = stats.norm.ppf(0.975)  # 1.96 approximately\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = critical_z_value * standard_error\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval_lower = sample_mean - margin_of_error\n",
    "confidence_interval_upper = sample_mean + margin_of_error\n",
    "\n",
    "# Print the results\n",
    "print(f\"Sample Mean: {sample_mean}\")\n",
    "print(f\"Confidence Interval: [{confidence_interval_lower:.2f}, {confidence_interval_upper:.2f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dea2075-d367-4c0a-977c-57f404e39f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The margin of error (MoE) in a confidence interval is a measure of the range around a point estimate (such as the sample mean) that captures the uncertainty of estimating a population parameter. It quantifies how much the point estimate might vary from the true population parameter. A larger margin of error indicates higher uncertainty, while a smaller margin of error indicates greater precision in the estimation.\\n\\nMathematically, the margin of error is often calculated using the formula:\\n\\n\\\\[ \\text{Margin of Error} = \\text{Critical Value} \\times \\text{Standard Error} \\\\]\\n\\nWhere:\\n- The critical value depends on the desired confidence level and the distribution (usually a t-distribution or z-distribution).\\n- The standard error of the sample mean is typically \\\\( \\x0crac{s}{\\\\sqrt{n}} \\\\), where \\\\( s \\\\) is the sample standard deviation and \\\\( n \\\\) is the sample size.\\n\\n**Effect of Sample Size on Margin of Error:**\\n\\nSample size directly affects the margin of error. As the sample size increases:\\n- The standard error decreases because the denominator of the standard error formula (\\\\( \\\\sqrt{n} \\\\)) increases.\\n- The critical value remains relatively constant for a given confidence level.\\n\\nAs a result, a larger sample size leads to a smaller margin of error, indicating a more precise estimation of the population parameter. In other words, larger sample sizes provide more information about the population and reduce the variability of the sample mean.\\n\\n**Example Scenario:**\\n\\nSuppose you are conducting a survey to estimate the average age of students in a university. You collect data from two different sample sizes: \\\\( n_1 = 50 \\\\) and \\\\( n_2 = 200 \\\\).\\n\\nFor both samples, you calculate the 95% confidence interval using the same formula and assuming the same standard deviation:\\n\\n\\\\[ \\text{Confidence Interval} = \\text{Sample Mean} \\\\pm \\text{Margin of Error} \\\\]\\n\\nAssuming a constant critical value for simplicity, you will observe that the margin of error for the larger sample (\\\\( n_2 = 200 \\\\)) is smaller than the margin of error for the smaller sample (\\\\( n_1 = 50 \\\\)).\\n\\nThis means that with the larger sample size, you have a more precise estimate of the population mean. The smaller margin of error indicates that the true population mean is likely to be closer to the sample mean, providing more confidence in your estimation.\\n\\nIn summary, the margin of error quantifies the uncertainty in a confidence interval estimation. Larger sample sizes lead to smaller margins of error, resulting in more precise estimates and greater confidence in the accuracy of the estimation.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 8\n",
    "\"\"\"The margin of error (MoE) in a confidence interval is a measure of the range around a point estimate (such as the sample mean) that captures the uncertainty of estimating a population parameter. It quantifies how much the point estimate might vary from the true population parameter. A larger margin of error indicates higher uncertainty, while a smaller margin of error indicates greater precision in the estimation.\n",
    "\n",
    "Mathematically, the margin of error is often calculated using the formula:\n",
    "\n",
    "\\[ \\text{Margin of Error} = \\text{Critical Value} \\times \\text{Standard Error} \\]\n",
    "\n",
    "Where:\n",
    "- The critical value depends on the desired confidence level and the distribution (usually a t-distribution or z-distribution).\n",
    "- The standard error of the sample mean is typically \\( \\frac{s}{\\sqrt{n}} \\), where \\( s \\) is the sample standard deviation and \\( n \\) is the sample size.\n",
    "\n",
    "**Effect of Sample Size on Margin of Error:**\n",
    "\n",
    "Sample size directly affects the margin of error. As the sample size increases:\n",
    "- The standard error decreases because the denominator of the standard error formula (\\( \\sqrt{n} \\)) increases.\n",
    "- The critical value remains relatively constant for a given confidence level.\n",
    "\n",
    "As a result, a larger sample size leads to a smaller margin of error, indicating a more precise estimation of the population parameter. In other words, larger sample sizes provide more information about the population and reduce the variability of the sample mean.\n",
    "\n",
    "**Example Scenario:**\n",
    "\n",
    "Suppose you are conducting a survey to estimate the average age of students in a university. You collect data from two different sample sizes: \\( n_1 = 50 \\) and \\( n_2 = 200 \\).\n",
    "\n",
    "For both samples, you calculate the 95% confidence interval using the same formula and assuming the same standard deviation:\n",
    "\n",
    "\\[ \\text{Confidence Interval} = \\text{Sample Mean} \\pm \\text{Margin of Error} \\]\n",
    "\n",
    "Assuming a constant critical value for simplicity, you will observe that the margin of error for the larger sample (\\( n_2 = 200 \\)) is smaller than the margin of error for the smaller sample (\\( n_1 = 50 \\)).\n",
    "\n",
    "This means that with the larger sample size, you have a more precise estimate of the population mean. The smaller margin of error indicates that the true population mean is likely to be closer to the sample mean, providing more confidence in your estimation.\n",
    "\n",
    "In summary, the margin of error quantifies the uncertainty in a confidence interval estimation. Larger sample sizes lead to smaller margins of error, resulting in more precise estimates and greater confidence in the accuracy of the estimation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f81768-aa37-48c9-a777-77ee3da7583c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The z-score (also known as the standard score) measures how many standard deviations a data point is away from the mean of a distribution. It's a way to standardize data and compare it to a standard normal distribution with a mean of 0 and a standard deviation of 1.\\n\\nThe formula to calculate the z-score is:\\n\\n\\\\[ z = \\x0crac{x - \\\\mu}{\\\\sigma} \\\\]\\n\\nWhere:\\n- \\\\( x \\\\) is the value of the data point.\\n- \\\\( \\\\mu \\\\) is the population mean.\\n- \\\\( \\\\sigma \\\\) is the population standard deviation.\\n\\nGiven the values:\\n- \\\\( x = 75 \\\\) (value of the data point)\\n- \\\\( \\\\mu = 70 \\\\) (population mean)\\n- \\\\( \\\\sigma = 5 \\\\) (population standard deviation)\\n\\nLet's calculate the z-score:\\n\\n\\\\[ z = \\x0crac{75 - 70}{5} = 1 \\\\]\\n\\n**Interpretation of Results:**\\n\\nA z-score of 1 means that the data point (75) is 1 standard deviation above the mean (70) of the distribution. This indicates that the value of 75 is relatively higher than the average value within the population by one standard deviation. In the context of a normal distribution, a z-score of 1 corresponds to a point that is in the 84th percentile, meaning that 84% of the data falls below this value.\\n\\nZ-scores are useful for comparing data points from different distributions or for identifying outliers. They provide a standardized measure of how much a data point deviates from the mean, regardless of the original scale of the data.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 9\n",
    "\"\"\"The z-score (also known as the standard score) measures how many standard deviations a data point is away from the mean of a distribution. It's a way to standardize data and compare it to a standard normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The formula to calculate the z-score is:\n",
    "\n",
    "\\[ z = \\frac{x - \\mu}{\\sigma} \\]\n",
    "\n",
    "Where:\n",
    "- \\( x \\) is the value of the data point.\n",
    "- \\( \\mu \\) is the population mean.\n",
    "- \\( \\sigma \\) is the population standard deviation.\n",
    "\n",
    "Given the values:\n",
    "- \\( x = 75 \\) (value of the data point)\n",
    "- \\( \\mu = 70 \\) (population mean)\n",
    "- \\( \\sigma = 5 \\) (population standard deviation)\n",
    "\n",
    "Let's calculate the z-score:\n",
    "\n",
    "\\[ z = \\frac{75 - 70}{5} = 1 \\]\n",
    "\n",
    "**Interpretation of Results:**\n",
    "\n",
    "A z-score of 1 means that the data point (75) is 1 standard deviation above the mean (70) of the distribution. This indicates that the value of 75 is relatively higher than the average value within the population by one standard deviation. In the context of a normal distribution, a z-score of 1 corresponds to a point that is in the 84th percentile, meaning that 84% of the data falls below this value.\n",
    "\n",
    "Z-scores are useful for comparing data points from different distributions or for identifying outliers. They provide a standardized measure of how much a data point deviates from the mean, regardless of the original scale of the data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284c03d9-9767-4a99-b9e3-a22f7bec5dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To conduct a hypothesis test to determine if the new weight loss drug is significantly effective, we need to set up the null hypothesis (H0) and the alternative hypothesis (Ha), choose a significance level (α), calculate the test statistic, and compare it to the critical value or calculate the p-value.\\n\\n**Given Data:**\\n- Sample Mean (\\\\( \\x08ar{x} \\\\)) = 6 pounds\\n- Sample Standard Deviation (\\\\( s \\\\)) = 2.5 pounds\\n- Sample Size (\\\\( n \\\\)) = 50\\n- Desired Confidence Level = 95%\\n- Significance Level (\\\\( \\x07lpha \\\\)) = 0.05 (for a two-tailed test)\\n\\n**Hypotheses:**\\n- Null Hypothesis (H0): The new weight loss drug is not significantly effective. \\\\( \\\\mu = 0 \\\\)\\n- Alternative Hypothesis (Ha): The new weight loss drug is significantly effective. \\\\( \\\\mu \\neq 0 \\\\)\\n\\n**Calculate the Test Statistic:**\\nThe formula for the t-test statistic for a one-sample t-test is:\\n\\n\\\\[ t = \\x0crac{\\x08ar{x} - \\\\mu}{\\x0crac{s}{\\\\sqrt{n}}} \\\\]\\n\\nPlugging in the given values:\\n\\n\\\\[ t = \\x0crac{6 - 0}{\\x0crac{2.5}{\\\\sqrt{50}}} \\x07pprox 12.68 \\\\]\\n\\n**Degrees of Freedom:**\\nThe degrees of freedom (\\\\( df \\\\)) for a one-sample t-test is \\\\( n - 1 \\\\). In this case, \\\\( df = 49 \\\\).\\n\\n**Critical Value or p-value:**\\nSince the test is two-tailed and we want a 95% confidence level, the critical t-values for a significance level of 0.025 on each tail can be found using a t-distribution table or a statistical software. For \\\\( df = 49 \\\\), the critical t-values are approximately \\\\( \\\\pm 2.0096 \\\\).\\n\\n**Conclusion:**\\nSince the calculated t-test statistic (\\\\( t = 12.68 \\\\)) is much larger than the critical t-value (\\\\( \\\\pm 2.0096 \\\\)), we can reject the null hypothesis. This means that the new weight loss drug is significantly effective at the 95% confidence level.\\n\\nAlternatively, you could calculate the p-value associated with the calculated t-test statistic and compare it to the significance level (\\\\( \\x07lpha = 0.05 \\\\)) to make the decision. A very small p-value would indicate strong evidence against the null hypothesis.\\n\\nIn either case, the result suggests that the new weight loss drug is effective in reducing weight among the participants.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 10\n",
    "\"\"\"To conduct a hypothesis test to determine if the new weight loss drug is significantly effective, we need to set up the null hypothesis (H0) and the alternative hypothesis (Ha), choose a significance level (α), calculate the test statistic, and compare it to the critical value or calculate the p-value.\n",
    "\n",
    "**Given Data:**\n",
    "- Sample Mean (\\( \\bar{x} \\)) = 6 pounds\n",
    "- Sample Standard Deviation (\\( s \\)) = 2.5 pounds\n",
    "- Sample Size (\\( n \\)) = 50\n",
    "- Desired Confidence Level = 95%\n",
    "- Significance Level (\\( \\alpha \\)) = 0.05 (for a two-tailed test)\n",
    "\n",
    "**Hypotheses:**\n",
    "- Null Hypothesis (H0): The new weight loss drug is not significantly effective. \\( \\mu = 0 \\)\n",
    "- Alternative Hypothesis (Ha): The new weight loss drug is significantly effective. \\( \\mu \\neq 0 \\)\n",
    "\n",
    "**Calculate the Test Statistic:**\n",
    "The formula for the t-test statistic for a one-sample t-test is:\n",
    "\n",
    "\\[ t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}} \\]\n",
    "\n",
    "Plugging in the given values:\n",
    "\n",
    "\\[ t = \\frac{6 - 0}{\\frac{2.5}{\\sqrt{50}}} \\approx 12.68 \\]\n",
    "\n",
    "**Degrees of Freedom:**\n",
    "The degrees of freedom (\\( df \\)) for a one-sample t-test is \\( n - 1 \\). In this case, \\( df = 49 \\).\n",
    "\n",
    "**Critical Value or p-value:**\n",
    "Since the test is two-tailed and we want a 95% confidence level, the critical t-values for a significance level of 0.025 on each tail can be found using a t-distribution table or a statistical software. For \\( df = 49 \\), the critical t-values are approximately \\( \\pm 2.0096 \\).\n",
    "\n",
    "**Conclusion:**\n",
    "Since the calculated t-test statistic (\\( t = 12.68 \\)) is much larger than the critical t-value (\\( \\pm 2.0096 \\)), we can reject the null hypothesis. This means that the new weight loss drug is significantly effective at the 95% confidence level.\n",
    "\n",
    "Alternatively, you could calculate the p-value associated with the calculated t-test statistic and compare it to the significance level (\\( \\alpha = 0.05 \\)) to make the decision. A very small p-value would indicate strong evidence against the null hypothesis.\n",
    "\n",
    "In either case, the result suggests that the new weight loss drug is effective in reducing weight among the participants.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b2c0551-bbe0-4a86-8ec5-1df030f0d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Proportion: 0.65\n",
      "Confidence Interval: [0.6082, 0.6918]\n"
     ]
    }
   ],
   "source": [
    "#que 11\n",
    "import math\n",
    "\n",
    "# Given data\n",
    "sample_proportion = 0.65  # Sample proportion\n",
    "sample_size = 500  # Sample size\n",
    "confidence_level = 0.95  # Confidence level\n",
    "\n",
    "# Calculate standard error\n",
    "standard_error = math.sqrt((sample_proportion * (1 - sample_proportion)) / sample_size)\n",
    "\n",
    "# Calculate critical z-value for a 95% confidence interval\n",
    "critical_z_value = stats.norm.ppf(1 - (1 - confidence_level) / 2)  # Approximately 1.96\n",
    "\n",
    "# Calculate margin of error\n",
    "margin_of_error = critical_z_value * standard_error\n",
    "\n",
    "# Calculate confidence interval\n",
    "confidence_interval_lower = sample_proportion - margin_of_error\n",
    "confidence_interval_upper = sample_proportion + margin_of_error\n",
    "\n",
    "# Print the results\n",
    "print(f\"Sample Proportion: {sample_proportion}\")\n",
    "print(f\"Confidence Interval: [{confidence_interval_lower:.4f}, {confidence_interval_upper:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2d341e-579e-42d2-b7ef-c72bd9b7f1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To conduct a hypothesis test to determine if there is a significant difference in student performance between two teaching methods, we need to perform a two-sample t-test. This type of test is used when comparing the means of two independent samples.\\n\\n**Given Data:**\\n- Sample A Mean (\\\\( \\x08ar{x}_A \\\\)) = 85\\n- Sample A Standard Deviation (\\\\( s_A \\\\)) = 6\\n- Sample A Size (\\\\( n_A \\\\)) = You haven't provided the sample size for sample A.\\n- Sample B Mean (\\\\( \\x08ar{x}_B \\\\)) = 82\\n- Sample B Standard Deviation (\\\\( s_B \\\\)) = 5\\n- Sample B Size (\\\\( n_B \\\\)) = You haven't provided the sample size for sample B.\\n- Significance Level (\\\\( \\x07lpha \\\\)) = 0.01\\n\\n**Hypotheses:**\\n- Null Hypothesis (H0): There is no significant difference in student performance between the two teaching methods. \\\\( \\\\mu_A - \\\\mu_B = 0 \\\\)\\n- Alternative Hypothesis (Ha): There is a significant difference in student performance between the two teaching methods. \\\\( \\\\mu_A - \\\\mu_B \\neq 0 \\\\)\\n\\n**Calculate the Test Statistic:**\\nThe formula for the two-sample t-test statistic is:\\n\\n\\\\[ t = \\x0crac{(\\x08ar{x}_A - \\x08ar{x}_B) - (\\\\mu_A - \\\\mu_B)}{\\\\sqrt{\\x0crac{s_A^2}{n_A} + \\x0crac{s_B^2}{n_B}}} \\\\]\\n\\nPlugging in the given values:\\n\\n\\\\[ t = \\x0crac{(85 - 82) - (0)}{\\\\sqrt{\\x0crac{6^2}{n_A} + \\x0crac{5^2}{n_B}}} \\\\]\\n\\nWe need the sample sizes (\\\\( n_A \\\\) and \\\\( n_B \\\\)) to proceed.\\n\\n**Degrees of Freedom:**\\nThe degrees of freedom (\\\\( df \\\\)) for a two-sample t-test is calculated using the formula:\\n\\n\\\\[ df = \\x0crac{\\\\left(\\x0crac{s_A^2}{n_A} + \\x0crac{s_B^2}{n_B}\\right)^2}{\\x0crac{\\\\left(\\x0crac{s_A^2}{n_A}\\right)^2}{n_A - 1} + \\x0crac{\\\\left(\\x0crac{s_B^2}{n_B}\\right)^2}{n_B - 1}} \\\\]\\n\\n**Critical Value or p-value:**\\nFor a two-tailed test with a significance level of 0.01, you would find the critical t-value using the degrees of freedom and the t-distribution table. Alternatively, you could calculate the p-value associated with the t-test statistic.\\n\\n**Conclusion:**\\nWith the given data, you need the sample sizes to proceed with the calculations. Once you have the sample sizes, you can calculate the t-test statistic, degrees of freedom, and make a decision based on the critical value or p-value. If the calculated t-test statistic is greater than the critical t-value or the p-value is less than the significance level (\\\\( \\x07lpha = 0.01 \\\\)), you would reject the null hypothesis and conclude that there is a significant difference in student performance between the two teaching methods.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#que 12\n",
    "\"\"\"To conduct a hypothesis test to determine if there is a significant difference in student performance between two teaching methods, we need to perform a two-sample t-test. This type of test is used when comparing the means of two independent samples.\n",
    "\n",
    "**Given Data:**\n",
    "- Sample A Mean (\\( \\bar{x}_A \\)) = 85\n",
    "- Sample A Standard Deviation (\\( s_A \\)) = 6\n",
    "- Sample A Size (\\( n_A \\)) = You haven't provided the sample size for sample A.\n",
    "- Sample B Mean (\\( \\bar{x}_B \\)) = 82\n",
    "- Sample B Standard Deviation (\\( s_B \\)) = 5\n",
    "- Sample B Size (\\( n_B \\)) = You haven't provided the sample size for sample B.\n",
    "- Significance Level (\\( \\alpha \\)) = 0.01\n",
    "\n",
    "**Hypotheses:**\n",
    "- Null Hypothesis (H0): There is no significant difference in student performance between the two teaching methods. \\( \\mu_A - \\mu_B = 0 \\)\n",
    "- Alternative Hypothesis (Ha): There is a significant difference in student performance between the two teaching methods. \\( \\mu_A - \\mu_B \\neq 0 \\)\n",
    "\n",
    "**Calculate the Test Statistic:**\n",
    "The formula for the two-sample t-test statistic is:\n",
    "\n",
    "\\[ t = \\frac{(\\bar{x}_A - \\bar{x}_B) - (\\mu_A - \\mu_B)}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}} \\]\n",
    "\n",
    "Plugging in the given values:\n",
    "\n",
    "\\[ t = \\frac{(85 - 82) - (0)}{\\sqrt{\\frac{6^2}{n_A} + \\frac{5^2}{n_B}}} \\]\n",
    "\n",
    "We need the sample sizes (\\( n_A \\) and \\( n_B \\)) to proceed.\n",
    "\n",
    "**Degrees of Freedom:**\n",
    "The degrees of freedom (\\( df \\)) for a two-sample t-test is calculated using the formula:\n",
    "\n",
    "\\[ df = \\frac{\\left(\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}\\right)^2}{\\frac{\\left(\\frac{s_A^2}{n_A}\\right)^2}{n_A - 1} + \\frac{\\left(\\frac{s_B^2}{n_B}\\right)^2}{n_B - 1}} \\]\n",
    "\n",
    "**Critical Value or p-value:**\n",
    "For a two-tailed test with a significance level of 0.01, you would find the critical t-value using the degrees of freedom and the t-distribution table. Alternatively, you could calculate the p-value associated with the t-test statistic.\n",
    "\n",
    "**Conclusion:**\n",
    "With the given data, you need the sample sizes to proceed with the calculations. Once you have the sample sizes, you can calculate the t-test statistic, degrees of freedom, and make a decision based on the critical value or p-value. If the calculated t-test statistic is greater than the critical t-value or the p-value is less than the significance level (\\( \\alpha = 0.01 \\)), you would reject the null hypothesis and conclude that there is a significant difference in student performance between the two teaching methods.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4d0de-58fa-481f-9179-982c0edbd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#que 13\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
